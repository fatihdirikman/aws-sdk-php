<?php
/**
 * Copyright 2010-2012 Amazon.com, Inc. or its affiliates. All Rights Reserved.
 *
 * Licensed under the Apache License, Version 2.0 (the "License").
 * You may not use this file except in compliance with the License.
 * A copy of the License is located at
 *
 * http://aws.amazon.com/apache2.0
 *
 * or in the "license" file accompanying this file. This file is distributed
 * on an "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either
 * express or implied. See the License for the specific language governing
 * permissions and limitations under the License.
 */

namespace Aws\Glacier\Model;

use Aws\Common\ChunkHash;
use Aws\Common\Enum\Size;
use Aws\Common\Exception\InvalidArgumentException;
use Aws\Common\Exception\OutOfBoundsException;
use Guzzle\Http\EntityBody;
use Guzzle\Http\EntityBodyInterface;

/**
 * Generates GlacierUpload objects from a string/stream that encapsulates the data needed for upload requests
 */
class UploadGenerator
{
    /**
     * @var array List of cached, valid upload part sizes for validation purposes
     */
    protected static $validPartSizes;

    /**
     * @var EntityBodyInterface The body of the upload represented as a Guzzle entity body
     */
    protected $body;

    /**
     * @var TreeHash The tree hash of the entire upload body
     */
    protected $treeHash;

    /**
     * @var array List of uploads generated by this generator
     */
    protected $uploads;

    /**
     * @var array The total size of the entire upload body
     */
    protected $archiveSize;

    /**
     * Creates a UploadGenerator and wraps the upload body in a Guzzle EntityBody object
     *
     * @param string|resource|EntityBodyInterface $body     The upload body
     * @param int                                 $partSize The size of parts to split the upload into
     *
     * @return self
     */
    public static function factory($body, $partSize = null)
    {
        return new self(EntityBody::factory($body), $partSize);
    }

    /**
     * @param EntityBodyInterface $body     The upload body
     * @param int                 $partSize The size of parts to split the upload into. Default is the 4GB max
     *
     * @throws InvalidArgumentException when the part size is invalid (i.e. not a power of 2 * 1MB)
     */
    public function __construct(EntityBodyInterface $body, $partSize = null)
    {
        $this->body = $body;
        $this->treeHash = new TreeHash();

        // The default/maximum upload/part size is 4GB
        $partSize = $partSize ?: 4 * Size::GB;

        // Setup valid part sizes (1MB-4GB where 2^N MB)
        if (!self::$validPartSizes) {
            self::$validPartSizes = array_map(function ($value) {
                return pow(2, $value) * Size::MB;
            }, range(0, 12));
        }

        // Make sure the part size is valid
        if (!in_array($partSize, self::$validPartSizes, true)) {
            throw new InvalidArgumentException('The part size must be a megabyte multiplied by a power of 2 and no'
                . 'greater than 4 gigabytes.');
        }

        $this->generateUploads($partSize);
    }

    /**
     * Returns a single upload object from the calculated uploads by index. By default it returns the first, which is
     * useful behavior if the part size was set to SINGLE_UPLOAD and there is only one upload.
     *
     * @param int $index The numerical index of the upload
     *
     * @return GlacierUpload
     * @throws InvalidArgumentException if the index is ambiguous
     * @throws OutOfBoundsException if the index of the upload doesn't exist
     */
    public function getSingleUpload($index = null)
    {
        // Make sure index is set if there is more than one upload
        if ($index === null && count($this->uploads) > 1) {
            throw new InvalidArgumentException('You must select an index if there is more than one part.');
        } else {
            $index = 0;
        }

        $index = (int) $index;

        // Get the upload at the index if it exists
        if (isset($this->uploads[$index])) {
            return $this->uploads[$index];
        } else {
            throw new OutOfBoundsException('An upload at that index did not exist.');
        }
    }

    /**
     * @return array
     */
    public function getUploads()
    {
        return $this->uploads;
    }

    /**
     * @return array
     */
    public function getArchiveSize()
    {
        return $this->archiveSize;
    }

    /**
     * @return string
     */
    public function getRootChecksum()
    {
        return $this->treeHash->getHash();
    }

    /**
     * Performs the work of reading the body stream, creating tree hashes, and creating GlacierUpload objects
     *
     * @param int $partSize The size of parts to split the upload into
     */
    protected function generateUploads($partSize)
    {
        // Rewind the body stream
        $this->body->seek(0);

        // Initialize variables for tracking data for upload
        $treeHash       = new TreeHash();
        $contentHash    = new ChunkHash();
        $uploadSize     = 0;
        $startingOffset = $this->body->ftell();

        // Read the data from the streamed body in 1MB chunks
        while ($data = $this->body->read(Size::MB)) {
            // Add data to the hashes and size calculations
            $treeHash->addData($data);
            $contentHash->addData($data);
            $uploadSize += strlen($data);

            // If the upload part is complete, generate an upload object and reset the currently tracked upload data
            if ($uploadSize === $partSize) {
                $this->uploads[] = $this->createUploadObject($treeHash, $contentHash, $uploadSize, $startingOffset);
                $treeHash        = new TreeHash();
                $contentHash     = new ChunkHash();
                $uploadSize      = 0;
                $startingOffset  = $this->body->ftell();
            }
        }

        // Handle any leftover data
        if ($uploadSize > 0) {
            $this->uploads[] = $this->createUploadObject($treeHash, $contentHash, $uploadSize, $startingOffset);
        }

        // Rewind the body stream
        $this->body->seek(0);
    }

    /**
     * Creates a Glacier Upload object
     *
     * @param TreeHash  $treeHash       Tree hash of upload
     * @param ChunkHash $contentHash    Content hash of upload
     * @param int       $uploadSize     Size of upload
     * @param int       $startingOffset Offset of the body for the upload
     *
     * @return GlacierUpload
     */
    protected function createUploadObject(TreeHash $treeHash, ChunkHash $contentHash, $uploadSize, $startingOffset)
    {
        // Add the checksum of the upload part to the tree hash of the archive
        $this->treeHash->addChecksum($treeHash->getHash(true), true);

        // Calculate the range and update the archive size
        $range = array($startingOffset, $startingOffset + $uploadSize - 1);
        $this->archiveSize += $uploadSize;

        // Return the created GlacierUpload value object
        return new GlacierUpload($treeHash->getHash(), $contentHash->getHash(), $uploadSize, $range, $this->body);
    }
}
